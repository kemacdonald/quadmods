---
title: "Quadrilateral learning experiments: Baseline"
date: "January 22, 2016"
output: html_document
---

```{r, echo = F}
rm(list=ls()) # clear workspace
knitr::opts_chunk$set(warning=FALSE, message=FALSE, sanitize = T, 
                      fig.height=4, fig.width=7, echo=F, cache = T)
```

```{r}
library(langcog)
library(dplyr)
library(ggplot2)
library(tidyr)
library(binom)
library(lme4)
library(bootstrap)
library(magrittr)
library(stringr)
theme_set(theme_bw())
```

Load data.

```{r data_clean}
d1 <- read.csv("../../data/baseline_expt/quadmods-baseline.csv", header=TRUE, 
               row.names=NULL, stringsAsFactors = FALSE)

d1 <- d1 %>% 
    distinct() %>% 
    mutate(block_num = as.numeric(block))
```

Get the block each ss reached criterion

```{r}
d1 %<>% 
    filter(trial_type == "training") %>% 
    group_by(subids) %>% 
    summarise(block_reached_crit = max(block_num)) %>% 
    left_join(., d1) %>% 
    mutate(reached_crit = ifelse(block_reached_crit < 15, "yes", "no"))
```

Descriptives
--------

### How many participants?

```{r}
d1 %>% 
    select(subids, reached_crit) %>% 
    unique() %>% 
    group_by(reached_crit) %>% 
    summarise(n_subs = n()) %>% 
    knitr::kable()
```

### How long did experiment take?

```{r}
d1 %>% 
    filter(trial_type == "training") %>%
    group_by(reached_crit) %>% 
    summarise(m_train_time_sec = (mean(trial_time) / 1000),
              m_exp_time_min = (mean(exp_time) / 1000) / 60) %>% 
    knitr::kable()

ss <- d1 %>% 
    filter(trial_type == "training") %>% 
    group_by(subids, reached_crit) %>% 
    summarise(train_time_sec = (mean(trial_time) / 1000),
              exp_time_min = (mean(exp_time) / 1000) / 60,
              max_training_block = max(as.numeric(block)))

ggplot(aes(x=exp_time_min, fill = reached_crit), data = ss) +
    geom_histogram(alpha = 0.7, binwidth = 2) +
    scale_fill_solarized() 
```

### How many blocks did it take to reach criterion? 

```{r}
ss <- d1 %>% 
    filter(trial_type == "training") %>% 
    group_by(subids) %>% 
    summarise(block_reached_crit = max(as.numeric(block)))

ggplot(data = ss, aes(x = block_reached_crit)) + 
    geom_histogram() +
    xlab("Block Reached Criterion") +
    theme(text = element_text(size = 20))
```

### Comments

```{r}
d1 %>% 
    distinct(subids) %>% 
    select(subids:exp_improve) %>% 
    knitr::kable()
```

Visualization
--------

### Training performance across blocks split by ss who reached training criterion

```{r}
ms <- d1 %>% 
    filter(trial_type == "training") %>% 
    group_by(block, reached_crit) %>% 
    multi_boot_standard(column = "correct") %>% 
    mutate(prob_error = 1 - mean)

ggplot(data = ms, aes(x = as.numeric(block), y = mean, color = reached_crit)) + 
    geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
    geom_line() +
    geom_hline(aes(yintercept = 0.5), linetype = "dashed") +
    ylim(0.2, 1) +
    scale_color_solarized() +
    xlab("Block") +
    theme(text = element_text(size = 20))
```

### Average blocks to criterion

```{r}
d1 %>% 
    filter(trial_type == "training") %>% 
    mutate(condition = "baseline") %>% 
    group_by(subids, condition) %>% 
    summarise(block_reached_crit = max(as.numeric(block))) %>% 
    filter(block_reached_crit != 15) %>% # remove ss who didn't reach criterion
    group_by(condition) %>% 
    multi_boot_standard(column = "block_reached_crit") %>% 
    knitr::kable()
```

### Relational test broken down by question and block

```{r, fig.width=9, fig.height=6}
ms <- d1 %>% 
    filter(trial_type %in% c("relational")) %>%
    group_by(question_and_shape, question, block = as.factor(block), reached_crit) %>%
    multi_boot_standard(column = "correct") %>% 
    ungroup() %>% 
    mutate(block = relevel(block, "pretest")) 

ggplot(aes(x = question_and_shape, y = mean, fill = block), data = ms) + 
    geom_bar(stat="identity", position="dodge", width = 0.5) +
    geom_linerange(aes( ymin = ci_lower, ymax = ci_upper),  
                   position = position_dodge(width = 0.5)) +
    geom_hline(yintercept = .5, lty = 2) +
    ylim(0, 1) + 
    xlab("Question") +
    scale_fill_solarized() +
    facet_grid(reached_crit~.) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 30, hjust = 1),
          text = element_text(size = 20)) +
    ggtitle("Are all _____ also ______?") 
```

### Overall accuracy analysis for relational test across blocks

```{r}
ms <- d1 %>% 
    filter(trial_type %in% c("relational")) %>% 
    group_by(trial_type, block = as.factor(block)) %>%
    multi_boot_standard(column = "correct")

ms %<>% mutate(chance_line = ifelse(trial_type == "relational", 0.5, 0.5),
               block = relevel(block, "pretest"))

ggplot(aes(x = block, y = mean), data = ms) +
    geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
    geom_line(aes(group=1)) +
    geom_hline(aes(yintercept = chance_line), linetype = "dashed") +
    ylim(0,1.0) +
    scale_color_solarized() 
```

### Within subjects change scores for all shapes

```{r}
ss_acc <- d1 %>% 
    filter(trial_type %in% c("relational")) %>% 
    group_by(subids, block, trial_type, reached_crit) %>% 
    summarise(m_acc = mean(correct)) %>% 
    spread(key = block, value = m_acc) %>% 
    mutate(m_diff_score = posttest - pretest)

ms_change <- ss_acc %>% 
    group_by(trial_type) %>% 
    multi_boot_standard(column = "m_diff_score")

ggplot(aes(x = trial_type, y = mean, fill = trial_type), 
       data = ms_change) +
    geom_bar(stat = "identity", width = 0.5) +
    geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
    geom_hline(yintercept = 0) +
    scale_fill_solarized() +
    ylim(-0.2, 0.2) + 
    guides(fill=F)
```

## Analysis splitting by ss who reached criterion

### Overall accuracy analysis

```{r}
ms <- d1 %>% 
    filter(trial_type %in% c("relational")) %>% 
    group_by(trial_type, block = as.factor(block), reached_crit) %>%
    multi_boot_standard(column = "correct")


ms %<>% ungroup() %>%  mutate(block = relevel(block, "pretest"))

ggplot(aes(x = block, y = mean), data = ms) +
    geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
    geom_line(aes(group=1)) +
    geom_hline(aes(yintercept = 0.5), linetype = "dashed") +
    ylim(0,1.0) +
    facet_grid(.~reached_crit) +
    scale_color_solarized() +
    theme_bw() +
    theme(text = element_text(size = 20))
```

### Within subjects change scores

```{r}
ss_acc <- d1 %>% 
    filter(trial_type %in% c("relational")) %>% 
    group_by(subids, block, trial_type, reached_crit) %>% 
    summarise(m_acc = mean(correct)) %>% 
    spread(key = block, value = m_acc) %>% 
    mutate(m_diff_score = posttest - pretest)

# filter out ss 3SD away from mean
ss_acc %<>%
    mutate(include = ifelse(abs(m_diff_score) > sd(ss_acc$m_diff_score) * 3 +
                                mean(ss_acc$m_diff_score),
                            "no", "yes"))

ms_change <- ss_acc %>% 
    filter(include == "yes") %>% 
    group_by(trial_type, reached_crit) %>% 
    multi_boot_standard(column = "m_diff_score")

ggplot(aes(x = trial_type, y = mean, fill = trial_type), 
       data = ms_change) +
    geom_bar(stat = "identity", width = 0.5) +
    geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
    facet_grid(.~reached_crit) +
    geom_hline(yintercept = 0) +
    scale_fill_solarized() +
    ylim(-0.2, 0.2) + 
    guides(fill=F) + 
    theme_bw()
```

## Split analysis by diagnostic items

Here we want ask whether performance on specific training trials gives us information about
who is likely to reach criterion in the passive training. Specifically, we want to know if
the first time you are asked about squares and rectangles or squares and rhombuses provides
evidence for your meta-theory or meta-understanding of the inclusional quadrilateral definitions.

```{r}


```
